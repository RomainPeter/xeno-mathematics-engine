"""
Interface en ligne de commande pour le Proof Engine for Code v0.
G√®re les commandes: plan-run, verify, audit-pack, metrics.
"""

import argparse
import json
import os
import sys
from typing import Any, Dict, List

from proofengine.core.schemas import PCAP, XState
from proofengine.core.state import create_initial_state
from planner.meta import MetacognitivePlanner
from runner.verifier import Verifier
from metrics.collect import MetricsCollector
from scripts.audit_pack import AuditPackGenerator


class ProofEngineCLI:
    """Interface en ligne de commande pour le Proof Engine."""

    def __init__(self):
        """Initialise le CLI."""
        self.parser = self._create_parser()
        self.planner = MetacognitivePlanner()
        self.verifier = Verifier()
        self.metrics_collector = MetricsCollector()
        self.audit_pack_generator = AuditPackGenerator()

    def _create_parser(self) -> argparse.ArgumentParser:
        """Cr√©e le parser d'arguments."""
        parser = argparse.ArgumentParser(
            description="Proof Engine for Code v0 - CLI",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
Exemples d'utilisation:
  python -m runner.cli plan-run --goal "sanitize input" --case sanitize_input
  python -m runner.cli verify --pcap out/pcap/action_001.json
  python -m runner.cli audit-pack --output out/audit/
  python -m runner.cli metrics --input out/pcap/ --output out/metrics/
            """,
        )

        subparsers = parser.add_subparsers(dest="command", help="Commandes disponibles")

        # Commande plan-run
        plan_parser = subparsers.add_parser("plan-run", help="Ex√©cuter un plan")
        plan_parser.add_argument("--goal", required=True, help="Objectif √† atteindre")
        plan_parser.add_argument("--case", help="Cas de test √† utiliser")
        plan_parser.add_argument("--seed", type=int, help="Graine pour la reproductibilit√©")
        plan_parser.add_argument("--budget", type=int, default=30000, help="Budget temps en ms")
        plan_parser.add_argument("--output", default="out/", help="R√©pertoire de sortie")

        # Commande verify
        verify_parser = subparsers.add_parser("verify", help="V√©rifier un PCAP")
        verify_parser.add_argument("--pcap", required=True, help="Fichier PCAP √† v√©rifier")
        verify_parser.add_argument("--output", help="Fichier de sortie pour le rapport")

        # Commande audit-pack
        audit_parser = subparsers.add_parser("audit-pack", help="G√©n√©rer un pack d'audit")
        audit_parser.add_argument("--input", default="out/pcap/", help="R√©pertoire des PCAPs")
        audit_parser.add_argument("--output", default="out/audit/", help="R√©pertoire de sortie")
        audit_parser.add_argument("--sign", action="store_true", help="Signer le pack d'audit")

        # Commande metrics
        metrics_parser = subparsers.add_parser("metrics", help="G√©n√©rer des m√©triques")
        metrics_parser.add_argument("--input", default="out/pcap/", help="R√©pertoire des PCAPs")
        metrics_parser.add_argument("--output", default="out/metrics/", help="R√©pertoire de sortie")
        metrics_parser.add_argument(
            "--format",
            choices=["json", "markdown"],
            default="json",
            help="Format de sortie",
        )

        return parser

    def run(self, args: List[str] = None) -> int:
        """Ex√©cute le CLI avec les arguments donn√©s."""
        if args is None:
            args = sys.argv[1:]

        parsed_args = self.parser.parse_args(args)

        if not parsed_args.command:
            self.parser.print_help()
            return 1

        try:
            if parsed_args.command == "plan-run":
                return self._run_plan(parsed_args)
            elif parsed_args.command == "verify":
                return self._run_verify(parsed_args)
            elif parsed_args.command == "audit-pack":
                return self._run_audit_pack(parsed_args)
            elif parsed_args.command == "metrics":
                return self._run_metrics(parsed_args)
            else:
                print(f"Commande inconnue: {parsed_args.command}")
                return 1

        except Exception as e:
            print(f"Erreur: {str(e)}")
            return 1

    def _run_plan(self, args: argparse.Namespace) -> int:
        """Ex√©cute la commande plan-run."""
        print(f"üéØ Ex√©cution du plan pour l'objectif: {args.goal}")

        # Cr√©er l'√©tat initial
        initial_state = self._create_initial_state(args.case)

        # Configurer le planificateur
        config = {"seed": args.seed, "budget": {"time_limit_ms": args.budget}}
        self.planner = MetacognitivePlanner(config)

        # Ex√©cuter le plan
        result = self.planner.execute_plan(initial_state, args.goal, config.get("budget"))

        # Sauvegarder les r√©sultats
        self._save_plan_results(result, args.output)

        if result["success"]:
            print("‚úÖ Plan ex√©cut√© avec succ√®s")
            return 0
        else:
            print("‚ùå Plan √©chou√©")
            return 1

    def _run_verify(self, args: argparse.Namespace) -> int:
        """Ex√©cute la commande verify."""
        print(f"üîç V√©rification du PCAP: {args.pcap}")

        # Charger le PCAP
        try:
            with open(args.pcap, "r") as f:
                pcap_data = json.load(f)
            pcap = PCAP(**pcap_data)
        except Exception as e:
            print(f"Erreur lors du chargement du PCAP: {e}")
            return 1

        # V√©rifier le PCAP
        verification_result = self.verifier.replay(pcap)

        # Sauvegarder le rapport
        if args.output:
            with open(args.output, "w") as f:
                json.dump(verification_result, f, indent=2, default=str)

        # Afficher le r√©sultat
        verdict = verification_result.get("verdict", "unknown")
        if verdict == "pass":
            print("‚úÖ PCAP v√©rifi√© avec succ√®s")
            return 0
        else:
            print(f"‚ùå PCAP √©chou√©: {verdict}")
            return 1

    def _run_audit_pack(self, args: argparse.Namespace) -> int:
        """Ex√©cute la commande audit-pack."""
        print(f"üì¶ G√©n√©ration du pack d'audit depuis: {args.input}")

        # G√©n√©rer le pack d'audit
        audit_pack = self.audit_pack_generator.generate_audit_pack(args.input, args.sign)

        # Sauvegarder le pack
        os.makedirs(args.output, exist_ok=True)
        output_file = os.path.join(args.output, "audit_pack.json")

        with open(output_file, "w") as f:
            f.write(audit_pack.to_json())

        print(f"‚úÖ Pack d'audit g√©n√©r√©: {output_file}")
        return 0

    def _run_metrics(self, args: argparse.Namespace) -> int:
        """Ex√©cute la commande metrics."""
        print(f"üìä G√©n√©ration des m√©triques depuis: {args.input}")

        # Collecter les m√©triques
        metrics = self.metrics_collector.collect_metrics(args.input)

        # Sauvegarder les m√©triques
        os.makedirs(args.output, exist_ok=True)

        if args.format == "json":
            output_file = os.path.join(args.output, "metrics.json")
            with open(output_file, "w") as f:
                json.dump(metrics, f, indent=2, default=str)
        else:  # markdown
            output_file = os.path.join(args.output, "metrics.md")
            with open(output_file, "w") as f:
                f.write(self._format_metrics_markdown(metrics))

        print(f"‚úÖ M√©triques g√©n√©r√©es: {output_file}")
        return 0

    def _create_initial_state(self, case: str = None) -> XState:
        """Cr√©e l'√©tat initial bas√© sur le cas."""
        if case == "sanitize_input":
            return create_initial_state(
                hypotheses={"input_sanitization_required"},
                evidences={"user_input_present"},
                obligations=[
                    {"policy": "pytest", "test_file": "test_sanitize.py"},
                    {"policy": "ruff", "max_issues": 0},
                    {
                        "policy": "forbidden_imports",
                        "forbidden_imports": ["eval", "exec"],
                    },
                ],
                artifacts=["sanitize_input.py"],
                sigma={"case": "sanitize_input", "timestamp": self._get_timestamp()},
            )
        elif case == "rate_limiter":
            return create_initial_state(
                hypotheses={"rate_limiting_required"},
                evidences={"api_endpoints_present"},
                obligations=[
                    {"policy": "pytest", "test_file": "test_rate_limit.py"},
                    {"policy": "mypy", "strict": True},
                    {"policy": "docstring", "required": True},
                ],
                artifacts=["rate_limiter.py"],
                sigma={"case": "rate_limiter", "timestamp": self._get_timestamp()},
            )
        elif case == "pure_fn":
            return create_initial_state(
                hypotheses={"pure_function_required"},
                evidences={"functional_programming_style"},
                obligations=[
                    {"policy": "pure_function", "no_side_effects": True},
                    {"policy": "type_hints", "required": True},
                    {"policy": "cyclomatic_complexity", "max_complexity": 5},
                ],
                artifacts=["pure_function.py"],
                sigma={"case": "pure_fn", "timestamp": self._get_timestamp()},
            )
        else:
            # √âtat par d√©faut
            return create_initial_state(
                hypotheses={"general_improvement"},
                evidences={"code_present"},
                obligations=[
                    {"policy": "pytest", "test_file": "test_general.py"},
                    {"policy": "ruff", "max_issues": 0},
                ],
                artifacts=["general.py"],
                sigma={"case": "general", "timestamp": self._get_timestamp()},
            )

    def _save_plan_results(self, result: Dict[str, Any], output_dir: str) -> None:
        """Sauvegarde les r√©sultats du plan."""
        os.makedirs(output_dir, exist_ok=True)

        # Sauvegarder l'√©tat final
        if "final_state" in result:
            state_file = os.path.join(output_dir, "final_state.json")
            with open(state_file, "w") as f:
                f.write(result["final_state"].to_json())

        # Sauvegarder l'historique d'ex√©cution
        if "execution_history" in result:
            history_file = os.path.join(output_dir, "execution_history.json")
            with open(history_file, "w") as f:
                json.dump(result["execution_history"], f, indent=2, default=str)

        # Sauvegarder les m√©triques
        if "metrics" in result:
            metrics_file = os.path.join(output_dir, "execution_metrics.json")
            with open(metrics_file, "w") as f:
                json.dump(result["metrics"], f, indent=2, default=str)

    def _format_metrics_markdown(self, metrics: Dict[str, Any]) -> str:
        """Formate les m√©triques en Markdown."""
        md = "# M√©triques du Proof Engine\n\n"

        if "total_pcaps" in metrics:
            md += "## R√©sum√©\n"
            md += f"- **Total PCAPs**: {metrics['total_pcaps']}\n"
            md += f"- **PCAPs r√©ussis**: {metrics.get('successful_pcaps', 0)}\n"
            md += f"- **Taux de succ√®s**: {metrics.get('success_rate', 0):.2%}\n\n"

        if "delta_analysis" in metrics:
            md += "## Analyse Delta\n"
            md += f"- **Delta moyen**: {metrics['delta_analysis'].get('average_delta', 0):.3f}\n"
            md += f"- **Delta max**: {metrics['delta_analysis'].get('max_delta', 0):.3f}\n\n"

        if "cost_analysis" in metrics:
            md += "## Analyse des Co√ªts\n"
            md += f"- **Co√ªt moyen**: {metrics['cost_analysis'].get('average_cost', 0):.2f}\n"
            md += f"- **Temps moyen**: {metrics['cost_analysis'].get('average_time_ms', 0)}ms\n\n"

        return md

    def _get_timestamp(self) -> str:
        """Retourne un timestamp format√©."""
        from datetime import datetime

        return datetime.now().isoformat()


def main():
    """Point d'entr√©e principal du CLI."""
    cli = ProofEngineCLI()
    return cli.run()


if __name__ == "__main__":
    sys.exit(main())
